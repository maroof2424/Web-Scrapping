 **ğŸ•¸ï¸ Day 7: Large-Scale Scraping with Scrapy & Automation** explained step-by-step, with extra clarity:

---

## ğŸ¯ **Goal:**

Use **Scrapy** to scrape data more efficiently â€” ideal for large-scale and automated scraping.

---

### âœ… **1. What is Scrapy?**

Scrapy is a **Python framework for web scraping** â€” fast, powerful, and great for crawling multiple pages or entire sites. It's better than BeautifulSoup for big projects.

---

### âœ… **2. Install Scrapy**

```bash
pip install scrapy
```

---

### âœ… **3. Start a Scrapy Project**

In your terminal, run:

```bash
scrapy startproject myproject
cd myproject
```

This creates the folder structure:

```
myproject/
â”œâ”€â”€ myproject/
â”‚   â””â”€â”€ settings.py, middlewares.py, etc.
â”œâ”€â”€ spiders/
â”‚   â””â”€â”€ your spiders go here
```

---

### âœ… **4. Create a Spider**

Inside the `spiders/` folder, create a file like `my_spider.py` and write:

```python
import scrapy

class MySpider(scrapy.Spider):
    name = "my_spider"
    start_urls = ["https://example.com"]

    def parse(self, response):
        title = response.css("title::text").get()
        yield {"title": title}
```

âœ… `name`: Spider name to run from command line
âœ… `start_urls`: List of URLs to start scraping
âœ… `parse`: A function that receives the response and extracts data

---

### âœ… **5. Run the Spider**

In the terminal:

```bash
scrapy crawl my_spider
```

---

### âœ… **6. Save Data to CSV or JSON**

```bash
scrapy crawl my_spider -o output.csv
# OR
scrapy crawl my_spider -o output.json
```

---

### âœ… **7. Use CSS Selectors / XPath in Scrapy**

```python
response.css("div.quote span.text::text").getall()
# or
response.xpath("//div[@class='quote']/span[@class='text']/text()").getall()
```

---

### âœ… **8. Practice Task:**

* Scrape all quotes & authors from [http://quotes.toscrape.com](http://quotes.toscrape.com) using Scrapy.
* Save them into a CSV file using `-o quotes.csv`.

